{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8c0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2141bab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  []\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용 확인\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e28da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f545c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d308c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886c17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_dim=1, hidden_dim=64, num_layers=2, output_dim=7, lookback=28):\n",
    "    model = keras.Sequential([\n",
    "        layers.LSTM(hidden_dim, return_sequences=True if num_layers > 1 else False),\n",
    "                #    input_shape=(lookback, input_dim)),\n",
    "        *[layers.LSTM(hidden_dim, return_sequences=False if i == num_layers-2 else True) \n",
    "          for i in range(num_layers-1)],\n",
    "        layers.Dense(output_dim)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0271e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(train_df):\n",
    "    trained_models = {}\n",
    "\n",
    "    for store_menu, group in tqdm(train_df.groupby(['영업장명_메뉴명']), desc='Training LSTM'):\n",
    "        store_train = group.sort_values('영업일자').copy()\n",
    "        if len(store_train) < LOOKBACK + PREDICT:\n",
    "            continue\n",
    "\n",
    "        features = ['매출수량']\n",
    "        scaler = MinMaxScaler()\n",
    "        store_train[features] = scaler.fit_transform(store_train[features])\n",
    "        train_vals = store_train[features].values  # shape: (N, 1)\n",
    "\n",
    "        # 시퀀스 구성\n",
    "        X_train, y_train = [], []\n",
    "        for i in range(len(train_vals) - LOOKBACK - PREDICT + 1):\n",
    "            X_train.append(train_vals[i:i+LOOKBACK])\n",
    "            y_train.append(train_vals[i+LOOKBACK:i+LOOKBACK+PREDICT, 0])\n",
    "\n",
    "        # numpy 배열로 변환\n",
    "        X_train = np.array(X_train).astype(np.float32)\n",
    "        y_train = np.array(y_train).astype(np.float32)\n",
    "\n",
    "        # 모델 생성 및 컴파일\n",
    "        model = create_lstm_model(input_dim=1, output_dim=PREDICT, lookback=LOOKBACK)\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        # 학습\n",
    "        model.fit(X_train, y_train, \n",
    "                 batch_size=BATCH_SIZE, \n",
    "                 epochs=EPOCHS, \n",
    "                 verbose=0)\n",
    "\n",
    "        trained_models[store_menu] = {\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'last_sequence': train_vals[-LOOKBACK:]  # (28, 1)\n",
    "        }\n",
    "\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e1a471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LSTM: 100%|██████████| 193/193 [41:18<00:00, 12.84s/it]\n",
      "Training LSTM: 100%|██████████| 193/193 [41:18<00:00, 12.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "trained_models = train_lstm(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad997734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lstm(test_df, trained_models, test_prefix: str):\n",
    "    results = []\n",
    "\n",
    "    for store_menu, store_test in test_df.groupby(['영업장명_메뉴명']):\n",
    "        key = store_menu\n",
    "        if key not in trained_models:\n",
    "            continue\n",
    "\n",
    "        model = trained_models[key]['model']\n",
    "        scaler = trained_models[key]['scaler']\n",
    "\n",
    "        store_test_sorted = store_test.sort_values('영업일자')\n",
    "        recent_vals = store_test_sorted['매출수량'].values[-LOOKBACK:]\n",
    "        if len(recent_vals) < LOOKBACK:\n",
    "            continue\n",
    "\n",
    "        # 정규화\n",
    "        recent_vals = scaler.transform(recent_vals.reshape(-1, 1))\n",
    "        x_input = np.array([recent_vals]).astype(np.float32)\n",
    "\n",
    "        # 예측\n",
    "        pred_scaled = model.predict(x_input, verbose=0)[0]\n",
    "\n",
    "        # 역변환\n",
    "        restored = []\n",
    "        for i in range(PREDICT):\n",
    "            dummy = np.zeros((1, 1))\n",
    "            dummy[0, 0] = pred_scaled[i]\n",
    "            restored_val = scaler.inverse_transform(dummy)[0, 0]\n",
    "            restored.append(max(restored_val, 0))\n",
    "\n",
    "        # 예측일자: TEST_00+1일 ~ TEST_00+7일\n",
    "        pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(PREDICT)]\n",
    "\n",
    "        for d, val in zip(pred_dates, restored):\n",
    "            results.append({\n",
    "                '영업일자': d,\n",
    "                '영업장명_메뉴명': store_menu,\n",
    "                '매출수량': val\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "# 모든 test_*.csv 순회\n",
    "test_files = sorted(glob.glob('data/TEST_*.csv'))\n",
    "\n",
    "for path in test_files:\n",
    "    test_df = pd.read_csv(path)\n",
    "\n",
    "    # 파일명에서 접두어 추출 (예: TEST_00)\n",
    "    filename = os.path.basename(path)\n",
    "    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n",
    "\n",
    "    pred_df = predict_lstm(test_df, trained_models, test_prefix)\n",
    "    all_preds.append(pred_df)\n",
    "    \n",
    "full_pred_df = pd.concat(all_preds, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n",
    "    # (영업일자, 메뉴) → 매출수량 딕셔너리로 변환\n",
    "    pred_dict = dict(zip(\n",
    "        zip(pred_df['영업일자'], pred_df['영업장명_메뉴명']),\n",
    "        pred_df['매출수량']\n",
    "    ))\n",
    "\n",
    "    final_df = sample_submission.copy()\n",
    "\n",
    "    for row_idx in final_df.index:\n",
    "        date = final_df.loc[row_idx, '영업일자']\n",
    "        for col in final_df.columns[1:]:  # 메뉴명들\n",
    "            final_df.loc[row_idx, col] = pred_dict.get((date, col), 0)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission = convert_to_submission_format(full_pred_df, sample_submission)\n",
    "submission.to_csv('baseline_tf_submission.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
